# ğŸ¬ CineGuard AI  
### Self-Learning Movie Review Manipulation Detection System

CineGuard AI is an end-to-end anomaly detection system that identifies potential movie review manipulation using behavioral signals from live OMDb API data.

This project demonstrates a complete Data Science pipeline including API ingestion, feature engineering, unsupervised learning, anomaly score calibration, secure API handling, and interactive deployment using Streamlit.

---

## ğŸ¥ Project Demo

<video src="assets/demo.mp4" controls width="800"></video>

---

## ğŸš€ Project Overview

Online movie ratings may exhibit abnormal engagement patterns due to artificial boosting or coordinated activity.

CineGuard AI detects **statistical anomalies** in rating behavior using an unsupervised learning approach.

The system:

- Fetches real-time movie data from OMDb API  
- Extracts behavioral features  
- Applies Isolation Forest for anomaly detection  
- Calibrates anomaly scores to a 0â€“100 Fraud Risk scale  
- Displays explainable results in a Streamlit dashboard  
- Stores searched movies in SQLite for future retraining  

---

## ğŸ§  Machine Learning Approach

### ğŸ”¹ Model Used
Isolation Forest (Unsupervised Anomaly Detection)

### ğŸ”¹ Why Unsupervised?
There is no publicly available labeled dataset for movie review manipulation.  
Therefore, anomaly detection is a practical solution.

### ğŸ”¹ Feature Engineering

The model uses:

- IMDb Rating  
- IMDb Vote Count  
- Runtime  
- Movie Age  
- Sentiment Score (TextBlob on plot summary)  
- Rating-Vote Ratio (rating / log(votes))  

### ğŸ”¹ Score Calibration

Raw anomaly scores from `decision_function()` are normalized using the training distribution range to produce a stable 0â€“100 Fraud Risk Score.

---

## ğŸ“Š Example Risk Predictions

Below are sample predictions generated by the system:

- ğŸŸ¢ Low Risk â†’ (Inception)  
- ğŸŸ¡ Moderate Risk â†’ (Dhurandhar)  
- ğŸ”´ High Risk â†’ (The Room)  

âš  Note:  
The system detects statistical anomalies in rating behavior, not confirmed fraud.

---

## ğŸ–¥ï¸ Streamlit Interface Features

- Smart movie search suggestions  
- Poster display  
- Fraud Risk Gauge (0â€“100)  
- Risk Classification:
  - ğŸŸ¢ Low Risk
  - ğŸŸ¡ Moderate Risk
  - ğŸ”´ High Risk
- Human-readable explanation  
- Secure API handling using `.env`

---

## ğŸ“‚ Project Structure



---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone Repository

git clone https://github.com/AryanDekate12/CineGuard-AI.git  
cd CineGuard-AI  

### 2ï¸âƒ£ Install Dependencies

pip install -r requirements.txt  

### 3ï¸âƒ£ Add OMDb API Key

Create a file named:

.env  

Inside it add:

OMDB_API_KEY=your_api_key_here  

### 4ï¸âƒ£ Train Model

Open:

cineguard_final.ipynb  

Run all cells and execute:

train_model()  

### 5ï¸âƒ£ Run Application

streamlit run app.py  

---

## ğŸ“Œ Limitations

- Detects statistical anomalies, not confirmed fraud  
- Does not analyze temporal rating spikes  
- Does not analyze full user review text  
- Depends on OMDb metadata  

---

## ğŸ”® Future Improvements

- Time-series anomaly detection  
- Transformer-based NLP review analysis  
- Confidence score output  
- Automated retraining scheduler  
- Model monitoring dashboard  

---

## ğŸ¯ Skills Demonstrated

- API Data Ingestion  
- Feature Engineering  
- Unsupervised Learning  
- Anomaly Score Calibration  
- SQLite Integration  
- Model Deployment (Streamlit)  
- Secure Environment Variable Handling  
- Production-Style Repository Structure  

---

## ğŸ‘¨â€ğŸ’» Author

Aryan Dekate  
Aspiring Data Scientist  

---

â­ If you found this project interesting, feel free to star the repository!
